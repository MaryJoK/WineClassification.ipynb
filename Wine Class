# ======================================|
#  DO NOT CHANGE ANYTHING IN THIS CELL! |
# ======================================|

%matplotlib inline

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import pandas as pd 

# Load the training data from 'data/wine_train.csv' into
# a pandas dataframe.

wine_train = pd.get_dummies(pd.read_csv('data/wine_train.csv', dtype={'Class': 'category'}))
wine_test = pd.get_dummies(pd.read_csv('data/wine_train.csv', dtype={'Class': 'category'})) 

# Display the first few rows from the dataframe
# to ensure proper loading

wine_train.head()

# Use the dataframe.count method to ensure
# all 148 records were loaded

wine_train.count()

# Declare placeholders and variables for your TensorFlow model here

x = tf.placeholder(tf.float32, [None, 13]) 
y_ = tf.placeholder(tf.float32, [None, 3])

# Define your TensorFlow model here

model_path = 'tmp/model.ckpt'

W = tf.Variable(tf.truncated_normal([13, 3], stddev=0.1)) 
b = tf.Variable(tf.zeros([3]))   
y = tf.nn.softmax(tf.matmul(x, W) + b) 

# Train the model in this cell

# Mean Squared Error
cost = tf.reduce_mean(tf.squared_difference(y_, y))

train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)

# Start a TensorFlow session
with tf.Session() as sess:

    # Initialize all of the Variables
    sess.run(tf.global_variables_initializer())
    
    # Operation for saving all variables
    saver = tf.train.Saver()
    
    # Training loop
    for epoch in range(epochs):
        avg_cost = 0.
        num_batches = int(wine_train.shape[0]/batch_size)
        
        for _ in range(num_batches):
            # Randomly select <batch_size> samples from the set (with replacement)
            batch = wine_train.sample(n=batch_size)

            # Capture the x and y_ data
            batch_features = batch.as_matrix()[:,:4]

            # get_dummies turns our categorical data into one-hot vectors
            batch_targets = pd.get_dummies(batch.Species).as_matrix()

            # Run the training step using batch_features and batch_targets
            # as x and y_, respectively and capture the cost at each step
            _, c = sess.run([train_step, cost], feed_dict={x:batch_features, y_:batch_targets})

            # Calculate the average cost for the epoch
            avg_cost += c/num_batches

        # Print epoch results
        print("Epoch %04d cost: %s" % (epoch + 1, "{:.4f}".format(avg_cost)))
    
    # If our model's most likely classification is equal to the one-hot index
    # add True to our correct_prediction tensor
    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))

    # Cast the boolean variables as floats and take the mean.
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    # Calculate the percentage of correct answers using the test data
    score = sess.run(accuracy, feed_dict={x: test_features, y_: test_targets}) * 100
    print("\nThe model correctly identified %s of the test data." % "{:.2f}%".format(score))

    # Save the model data
    save_path = saver.save(sess, model_path)
    print("\nModel data saved to %s" % model_path)
    
    # Run the trained model on 'data/wine_test.csv' here.
# Be sure to print out the accuracy!

# Hyperparameters 
learn_rate = .5
batch_size = 10
epochs = 50 
